// api/generate-render/route.ts
import OpenAI from "openai";
import { randomUUID } from "crypto";
import { NextResponse } from 'next/server';

export const runtime = "nodejs";
export const dynamic = "force-dynamic";

// --- í”„ë¡¬í”„íŠ¸ í—¬í¼ í•¨ìˆ˜ë“¤ (ê¸°ì¡´ ë¡œì§ ë³µêµ¬) ---
const baseRenderPrompt = () => `High-quality 3D studio product render of a LEGO-like brick-built model. Clean off-white background (#FAF9F6). Soft studio lighting, realistic plastic material, visible studs, premium product photography look. No text, no logos.`;

const subjectAddon = (type: string) => {
  const addons: Record<string, string> = {
    person: "Convert into a brick-built bust statue. Preserve hairstyle and clothing colors.",
    architecture: "Convert into a brick-built architecture set. Preserve facade shapes.",
    vehicle: "Convert into a brick-built vehicle. Preserve wheelbase and iconic curves.",
    animal: "Convert into a brick-built creature. Preserve silhouette with brick geometry.",
  };
  return addons[type] || "Convert the subject into a detailed brick-built model.";
};

// --- í•µì‹¬ API ë¡œì§ ---
export async function POST(req: Request) {
  try {
    const { inputImageUrl } = await req.json();
    if (!inputImageUrl) return NextResponse.json({ error: "URLì´ ì—†ìŠµë‹ˆë‹¤." }, { status: 400 });

    const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

    // 1. OpenAI Vision ë¶„ì„ (gpt-4o-mini)
    console.log("ğŸ” ë¶„ì„ ì‹œì‘...");
    const visionRes = await openai.chat.completions.create({
      model: "gpt-4o-mini",
      response_format: { type: "json_object" },
      messages: [
        { role: "system", content: "Analyze the image and return JSON: {subject_type, key_features: [], camera_hint}." },
        { role: "user", content: [{ type: "text", text: "Analyze this image for brick conversion." }, { type: "image_url", image_url: { url: inputImageUrl } }] }
      ]
    });

    const analysis = JSON.parse(visionRes.choices[0].message.content || "{}");
    const finalPrompt = `${baseRenderPrompt()} ${subjectAddon(analysis.subject_type)} Camera: ${analysis.camera_hint || 'three-quarter'}.`;

    // 2. Gemini ì´ë¯¸ì§€ ìƒì„± (fetch ì‚¬ìš©)
    console.log("ğŸ¨ Gemini ë Œë”ë§ ì‹œì‘...");
    const geminiRes = await fetch(
      `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-preview-image-generation:generateContent?key=${process.env.GEMINI_API_KEY}`,
      {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          contents: [{ role: "user", parts: [{ text: finalPrompt }] }],
          generationConfig: { responseModalities: ["TEXT", "IMAGE"] }
        })
      }
    );

    const geminiData = await geminiRes.json();
    const b64Image = geminiData.candidates?.[0]?.content?.parts?.find((p: any) => p.inlineData)?.inlineData?.data;

    if (!b64Image) throw new Error("Geminiê°€ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.");

    // 3. ìµœì¢… ê²°ê³¼ ë°˜í™˜
    return NextResponse.json({
      jobId: randomUUID(),
      previewImageUrl: `data:image/png;base64,${b64Image}`,
      partsSummary: "ì•½ 1,200ê°œì˜ ë¸Œë¦­ ë¶€í’ˆì´ í•„ìš”í•©ë‹ˆë‹¤.",
      storyText: `${analysis.subject_type}ì„(ë¥¼) ëª¨í‹°ë¸Œë¡œ í•œ ë‚˜ë§Œì˜ ë¸Œë¦­ ì•„íŠ¸ê°€ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤!`
    });

  } catch (error: any) {
    console.error("ğŸ”¥ Engine Error:", error.message);
    return NextResponse.json({ error: error.message }, { status: 500 });
  }
}